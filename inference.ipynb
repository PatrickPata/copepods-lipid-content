{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "from fastai.vision.all import *\n",
    "# from fastai.vision.all import load_learner\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "np.int = np.int32 # Need to add this to make preset model work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mask2(source: Image.Image, truth: np.ndarray, pred: np.ndarray) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Given source black and white image, true and predicted mask this function returns image\n",
    "    with areas colored as following:\n",
    "    - Green - annotation only\n",
    "    - Red - prediction only\n",
    "    - Yellow - overlap\n",
    "    \"\"\"\n",
    "    source = source.convert('RGBA')\n",
    "    M = np.zeros((*truth.shape, 4), dtype=np.uint8)\n",
    "    M[:, :, 1] = truth[:, :] * 255\n",
    "    M[:, :, 0] = pred[:, :] * 255\n",
    "    M[:, :, 3] = ((truth > 0) | (pred > 0)) * 75\n",
    "    \n",
    "    mask = Image.fromarray(M, 'RGBA')\n",
    "    return Image.alpha_composite(source, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2segmentation_path(imgpath: Path) -> Path:\n",
    "    return Path(str(imgpath).replace(\"images\", \"segmentations\"))\n",
    "\n",
    "def pixels2area(n: int) -> float:\n",
    "    \"\"\"Converts number of pixels into area in um^2\"\"\"\n",
    "    return n * 0.023 * 0.023\n",
    "\n",
    "def area2mass(A: float) -> float:\n",
    "    \"\"\"Converts area in um^2 into mass in mg\"\"\"\n",
    "    return 0.197 * (A ** 1.38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO fix this section wherein the conditional batch norm needs to be read\n",
    "import torch.nn as nn\n",
    "# Function to modify BatchNorm layers\n",
    "def modify_batchnorm(module):\n",
    "    for child_name, child in module.named_children():\n",
    "        if isinstance(child, nn.BatchNorm2d):\n",
    "            # Replace BatchNorm2d with a conditional version or skip logic\n",
    "            setattr(module, child_name, ConditionalBatchNorm(child.num_features))\n",
    "        else:\n",
    "            modify_batchnorm(child)\n",
    "\n",
    "# Define a custom conditional batch normalization layer\n",
    "class ConditionalBatchNorm(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(ConditionalBatchNorm, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(num_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply BatchNorm only if the spatial dimensions are greater than 1\n",
    "        if x.size(2) > 1 and x.size(3) > 1:\n",
    "            return self.bn(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "# Other modules needed from training\n",
    "class CombinedLoss:\n",
    "    \"Dice and Focal combined\"\n",
    "    def __init__(self, axis=1, smooth=1., alpha=1.):\n",
    "        store_attr()\n",
    "        self.focal_loss = FocalLossFlat(axis=axis)\n",
    "        self.dice_loss =  DiceLoss(axis, smooth)\n",
    "        \n",
    "    def __call__(self, pred, targ):\n",
    "        return self.focal_loss(pred, targ) + self.alpha * self.dice_loss(pred, targ)\n",
    "    \n",
    "    def decodes(self, x):    return x.argmax(dim=self.axis)\n",
    "    def activation(self, x): return F.softmax(x, dim=self.axis)\n",
    "\n",
    "def IoU(preds:Tensor, targs:Tensor, eps:float=1e-8):\n",
    "    \"\"\"Computes the Jaccard loss, a.k.a the IoU loss.\n",
    "    Notes: [Batch size,Num classes,Height,Width]\n",
    "    Args:\n",
    "        targs: a tensor of shape [B, H, W] or [B, 1, H, W].\n",
    "        preds: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model. (prediction)\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        iou: the average class intersection over union value \n",
    "             for multi-class image segmentation\n",
    "    \"\"\"\n",
    "    num_classes = preds.shape[1]\n",
    "    \n",
    "    # Single class segmentation?\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[targs.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(preds)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "        \n",
    "    # Multi-class segmentation\n",
    "    else:\n",
    "        # Convert target to one-hot encoding\n",
    "        # true_1_hot = torch.eye(num_classes)[torch.squeeze(targs,1)]\n",
    "        true_1_hot = torch.eye(num_classes)[targs.squeeze(1)]\n",
    "        \n",
    "        # Permute [B,H,W,C] to [B,C,H,W]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        \n",
    "        # Take softmax along class dimension; all class probs add to 1 (per pixel)\n",
    "        probas = F.softmax(preds, dim=1)\n",
    "        \n",
    "    true_1_hot = true_1_hot.type(preds.type())\n",
    "    \n",
    "    # Sum probabilities by class and across batch images\n",
    "    dims = (0,) + tuple(range(2, targs.ndimension()))\n",
    "    intersection = torch.sum(probas * true_1_hot, dims) # [class0,class1,class2,...]\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)  # [class0,class1,class2,...]\n",
    "    union = cardinality - intersection\n",
    "    iou = (intersection / (union + eps)).mean()   # find mean of class IoU values\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_learner(\"models/learner_down4_1015.pkl\", cpu=True)  # File models/learner.pkl\n",
    "model.load(\"model_resnet34_1015\")  # File models/model_resnet34.pth\n",
    "model.dls.device = 'cpu' # PP? Why is it ran with the cpu and not the gpu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs = sorted(list(Path(\"images/example_inputs_orig\").glob(\"*.bmp\")))\n",
    "\n",
    "# imgs = sorted(list(Path(\"../downscaled_4/data/images_processed\").glob(\"*.bmp\")))\n",
    "# imgs = sorted(list(Path(\"images/example_inputs_lowres\").glob(\"*.bmp\")))\n",
    "# imgs = sorted(list(Path(\"images/example_inputs_lowres2\").glob(\"*.bmp\")))\n",
    "\n",
    "# The UVP images\n",
    "# imgs = sorted(list(Path(\"../uvp_images/UVP6_darkedge_copepod_black_bg\").glob(\"*.png\")))\n",
    "imgs = sorted(list(Path(\"../uvp_images/UVP5_inverted_images\").glob(\"*.jpg\")))\n",
    "\n",
    "imgs = imgs[1:100]\n",
    "# imgs\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%skip\n",
    "# Can delete this section\n",
    "pimg = imgs[1]\n",
    "im = Image.open(pimg)\n",
    "p_segmentation = image2segmentation_path(pimg)\n",
    "display(im)\n",
    "display(p_segmentation)\n",
    "mask, *_ = model.predict(pimg)\n",
    "im_pred_mask = mask.numpy()\n",
    "im_truth = np.array(Image.open(p_segmentation).convert(\"L\"))\n",
    "\n",
    "print(im.shape)\n",
    "display(im_truth)\n",
    "print(im_truth.shape)\n",
    "\n",
    "img_with_masks = add_mask2(im, im_truth, im_pred_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pimg in imgs:\n",
    "    im = Image.open(pimg)\n",
    "    p_segmentation = image2segmentation_path(pimg)\n",
    "\n",
    "    # Predict returns the decoded prediction, index of the predicted class, and tensor of probabilities (but here\n",
    "    #  only the decoded prediction is retained/\n",
    "    mask, *_ = model.predict(pimg)\n",
    "    im_pred_mask = mask.numpy()\n",
    "\n",
    "    # if p_segmentation is not None:\n",
    "    #     im_truth = np.array(Image.open(p_segmentation).convert(\"L\"))\n",
    "    # else:\n",
    "    #     im_truth = np.zeros_like(im_pred_mask)\n",
    "\n",
    "    # if there are no true segmentation files at all:\n",
    "    im_truth = np.zeros_like(im_pred_mask)\n",
    "\n",
    "    img_with_masks = add_mask2(im, im_truth, im_pred_mask)\n",
    "\n",
    "    lipid_annotated = area2mass(pixels2area((im_truth > 0).sum()))\n",
    "    lipid_predicted = area2mass(pixels2area((im_pred_mask > 0.5).sum()))\n",
    "    print(\"************************\")\n",
    "    print(pimg)\n",
    "    print(f\"Lipid annotation: {lipid_annotated:.5}mg\")\n",
    "    print(f\"Lipid prediction: {lipid_predicted:.5}mg\")\n",
    "    # Green - annotation\n",
    "    # Red - prediction\n",
    "    # Yellow - overlap\n",
    "    display(img_with_masks.convert(\"RGB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Add some segmentation diagnostics and output the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "651d16dc913c4430c441d6ee5dd40dcae41b3f524f6b630523e4f72fa267ffa8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
