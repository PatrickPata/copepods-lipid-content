{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a cleanest notebook, more for archiving purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from utils import (\n",
    "    generic_image_path,\n",
    "    generic_image_path_processed,\n",
    "    generic_segmentation_path,\n",
    "    generic_segmentation_path_processed,\n",
    "    paste_imgs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mask(source: Image.Image, mask: Image.Image) -> Image.Image:\n",
    "    source = source.convert('RGBA')\n",
    "    # mask = Image.fromarray(np.r_[mask] * 255).convert('RGBA')\n",
    "    mask = mask.convert('RGBA')\n",
    "    M = np.r_[mask]\n",
    "    M[:, :, 1:2] = 0\n",
    "    M[:, :, 3] = 120\n",
    "    \n",
    "    mask = Image.fromarray(M)\n",
    "    return Image.alpha_composite(source, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = generic_image_path(root)\n",
    "image_path_processed = generic_image_path_processed(root)\n",
    "segmentation_path = generic_segmentation_path(root)\n",
    "segmentation_path_processed = generic_segmentation_path_processed(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(p:Path):\n",
    "    return segmentation_path_processed(p.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['segmentation_file_processed'] = df.filename.apply(segmentation_path_processed)\n",
    "df['image_file_processed'] = df.filename.apply(image_path_processed)\n",
    "\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Could not do one pass in your dataloader, there is something wrong in it\n"
     ]
    }
   ],
   "source": [
    "dls = DataBlock(\n",
    "    blocks=(ImageBlock, MaskBlock(codes=[\"nothing\", \"lipid_sac\"])),\n",
    "    get_x=ColReader(\"image_file_processed\"),\n",
    "    get_y=ColReader(\"segmentation_file_processed\"),\n",
    "    splitter=ColSplitter(\"is_valid\"),\n",
    "    #splitter=RandomSplitter(valid_pct=0.8, seed=42),\n",
    "    batch_tfms=[Normalize.from_stats(*imagenet_stats), *aug_transforms(pad_mode='zeros', max_rotate=180, max_zoom = 2, )]\n",
    ").dataloaders(df, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss:\n",
    "    \"Dice and Focal combined\"\n",
    "    def __init__(self, axis=1, smooth=1., alpha=1.):\n",
    "        store_attr()\n",
    "        self.focal_loss = FocalLossFlat(axis=axis)\n",
    "        self.dice_loss =  DiceLoss(axis, smooth)\n",
    "        \n",
    "    def __call__(self, pred, targ):\n",
    "        return self.focal_loss(pred, targ) + self.alpha * self.dice_loss(pred, targ)\n",
    "    \n",
    "    def decodes(self, x):    return x.argmax(dim=self.axis)\n",
    "    def activation(self, x): return F.softmax(x, dim=self.axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(preds:Tensor, targs:Tensor, eps:float=1e-8):\n",
    "    \"\"\"Computes the Jaccard loss, a.k.a the IoU loss.\n",
    "    Notes: [Batch size,Num classes,Height,Width]\n",
    "    Args:\n",
    "        targs: a tensor of shape [B, H, W] or [B, 1, H, W].\n",
    "        preds: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model. (prediction)\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        iou: the average class intersection over union value \n",
    "             for multi-class image segmentation\n",
    "    \"\"\"\n",
    "    num_classes = preds.shape[1]\n",
    "    \n",
    "    # Single class segmentation?\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[targs.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(preds)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "        \n",
    "    # Multi-class segmentation\n",
    "    else:\n",
    "        # Convert target to one-hot encoding\n",
    "        # true_1_hot = torch.eye(num_classes)[torch.squeeze(targs,1)]\n",
    "        true_1_hot = torch.eye(num_classes)[targs.squeeze(1)]\n",
    "        \n",
    "        # Permute [B,H,W,C] to [B,C,H,W]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        \n",
    "        # Take softmax along class dimension; all class probs add to 1 (per pixel)\n",
    "        probas = F.softmax(preds, dim=1)\n",
    "        \n",
    "    true_1_hot = true_1_hot.type(preds.type())\n",
    "    \n",
    "    # Sum probabilities by class and across batch images\n",
    "    dims = (0,) + tuple(range(2, targs.ndimension()))\n",
    "    intersection = torch.sum(probas * true_1_hot, dims) # [class0,class1,class2,...]\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)  # [class0,class1,class2,...]\n",
    "    union = cardinality - intersection\n",
    "    iou = (intersection / (union + eps)).mean()   # find mean of class IoU values\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_loss = CombinedLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = unet_learner(dls, resnet34, loss_func=combined_loss, metrics=[IoU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = []\n",
    "cbs.append(EarlyStoppingCallback(patience=5))\n",
    "cbs.append(SaveModelCallback(fname=\"model_resnet34\"))\n",
    "cbs.append(GradientAccumulation(n_acc=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = unet_learner(dls, resnet34)\n",
    "\n",
    "learn.fine_tune(40, cbs=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(\"models/learner.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"model_backup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2 = load_learner(\"models/learner.pkl\", cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2.load(\"model_resnet34_after26\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls2 = DataBlock(\n",
    "    blocks=(ImageBlock, MaskBlock(codes=[\"nothing\", \"lipid_sac\"])),\n",
    "    get_x=ColReader(\"image_file_processed\"),\n",
    "    get_y=ColReader(\"segmentation_file_processed\"),\n",
    "    splitter=ColSplitter(\"is_valid\"),\n",
    "    batch_tfms=[Normalize.from_stats(*imagenet_stats)]\n",
    ").dataloaders(df, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = learn2.get_preds(dl=dls2[1], reorder=False, with_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b87976caf3c7106082cf1714fc5ebab64a09dc193e0bee06d509a95d77726b49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
